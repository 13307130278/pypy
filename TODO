------------------------------------------------------------

looking at trace of fibo.tlc (targettlc.py), there are a lot
of read-barriers followed by write-barriers. Merging them
and making the first a write-barrier is important!
(attention: changing A2R->A2W after having placed the barrier
must still invalidate all A2R at the point of the new A2W)

------------------------------------------------------------

we have crashes when setting trace_eagerness very low
-> many guards generated.
It may be because patching the assembler code is not atomic.
(unlikely after trying to (badly) synchronize code around
places that patch assembler)
Maybe solve by new stmgc library function that synchronizes
all threads so only the caller is running.

------------------------------------------------------------

stmgc-library: since we copy back over h_originals, it may
make sense to treat them differently during allocation and
collection.
E.g. have a separate space to allocate h_originals from.
Thus, we have a more compact layout in memory (fragmentation).

------------------------------------------------------------

make stm_transaction_break use cond_call (or other ways to not
spill all registers)

------------------------------------------------------------

constptrs always require slowpath of read_barrier if they
point to a stub
they also always require the slowpath of a write-barrier
because there is always one indirection to the current version

------------------------------------------------------------

we may have too many transaction breaks in jitted code.

------------------------------------------------------------

unregister constptrs in stmgc when freeing traces

------------------------------------------------------------

stm-jitdriver with autoreds

------------------------------------------------------------

try to let non-atomic inevitable transactions run for longer, until
another thread starts waiting for the mutex

------------------------------------------------------------

RPyAssert(i < len(lst)): if lst is global this turns into tons of code

------------------------------------------------------------

GC: major collections; call __del__()

------------------------------------------------------------

JIT: finish (missing: the call in execute_token(), reorganize pypy source, ?)

------------------------------------------------------------

optimize the static placement of the STM_XxxBARRIERs and use them in JIT

------------------------------------------------------------



Current optimization opportunities (outside the JIT)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

tweak translator/stm/ to improve placement of barriers, at least at
whole-function level, but maybe cross-function; and reintroduce tweaks
to the PyFrame object (make sure it's always written and don't put more
barriers)

in parallel, tweak the API of stmgc: support "tentative" write_barrier calls
that are not actually followed by a write (checked by comparing the
object contents)

in the interpreter, e.g. BINARY_ADD calls space.add() which possibly
(but rarely) can cause a transaction break, thus requiring that the
frame be write-barrier()-ed again.  I'm thinking about alternatives for
this case: e.g. have a separate stack of objects, and the top-most
object on this stack is always in write mode.  so just after a
transaction break, we force a write barrier on the top object of the
stack.  this would be needed to avoid the usually-pointless write
barriers on the PyFrame everywhere in the interpreter

running valgrind we can see X% of the time in the read or write
barriers, but it would be interesting to know also the time spent in the
fast-path, as well as splitting it based e.g. on the RPython type of
object.  See also vtune.

JIT
~~~

* use specialized barriers in JIT
* optimize produced assembler code
* avoid calling aroundstate.after() for call_release_gil and instead
  start a normal transaction after the call
* maybe GUARD_NOT_INEVITABLE after call_may_force, call_assembler
  which is a small check if we are inevitable and does a transaction_break
  if we are.
* look at XXXs for STM everywhere
